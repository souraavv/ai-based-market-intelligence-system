{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pylab as pylab\n",
    "# params = {'legend.fontsize': 18,\n",
    "#           'figure.figsize': (15, 5),\n",
    "#          'axes.labelsize': 18,\n",
    "#          'axes.titlesize':18,\n",
    "#          'xtick.labelsize':18,\n",
    "#          'ytick.labelsize':18}\n",
    "# pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = 'Rajasthan'\n",
    "mandi = 'Kota'\n",
    "exp_no = 52\n",
    "retrainFreq = 15\n",
    "actualPricesFilePath = os.path.join(f'../Data/PlottingData/SOYABEAN/ARIMA_Interpolated_Data/', f'{state.upper()}_{mandi.upper()}_Price.csv')\n",
    "recommendationFilePath = f'./EXP{exp_no}_{state.upper()}_{mandi.upper()}/Recommendations/RetrainFreq{retrainFreq}Day/'\n",
    "withErrorModelFilePath = os.path.join(recommendationFilePath, 'WithErrorModels')\n",
    "withoutErrorModelFilePath = os.path.join(recommendationFilePath, 'WithoutErrorModels')\n",
    "processedFilePath = os.path.join(recommendationFilePath, 'Processed')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renameFiles(path, pattern, rpattern):\n",
    "    comp = re.compile(pattern)\n",
    "    for f in os.listdir(path):\n",
    "        full_path = os.path.join(path, f)\n",
    "        if os.path.isfile(full_path):\n",
    "            match = comp.search(f)\n",
    "            if not match :\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                new_name = match.expand(rpattern)\n",
    "                new_name = os.path.join(path, new_name)\n",
    "            except re.error:\n",
    "                continue\n",
    "        \n",
    "            if os.path.isfile(new_name):\n",
    "                print('%s -> %s skipped' % (f, new_name))\n",
    "            else:\n",
    "                os.rename(full_path, new_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern, rpattern = r'^recommend_with_errormodel_(\\d{0,4}).csv$', r\"Day_\\1.csv\"\n",
    "renameFiles(withErrorModelFilePath, pattern, rpattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern, rpattern = r'^recommend_without_errormodel_(\\d{0,4}).csv$', r\"Day_\\1.csv\"\n",
    "renameFiles(withoutErrorModelFilePath, pattern, rpattern)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processFile(recommendationsPath, actualPath):\n",
    "    actual_df = pd.read_csv(actualPath, index_col=['DATE'])\n",
    "    res = pd.DataFrame()\n",
    "    all_files = os.listdir(recommendationsPath)\n",
    "    all_files.sort()\n",
    "    for fileName in all_files:\n",
    "        print(f\"-- Processed {fileName} --\")\n",
    "        path = os.path.join(recommendationsPath, fileName)\n",
    "        r_df = pd.read_csv(path, index_col=['DATE'])\n",
    "        a_df = actual_df[actual_df.index.isin(r_df.index)]\n",
    "        \n",
    "        curr_day = {}\n",
    "        curr_day['DATE'] = a_df.index[0]\n",
    "        curr_day['ACTUAL_PRICE'] = a_df.iloc[0]['PRICE'] # Actual price of day_0\n",
    "        curr_day['ACTUAL_MAX'] = a_df[['PRICE']].max().iat[0]\n",
    "\n",
    "        # Without Prospect Theory\n",
    "        curr_day['MEAN_PRICE'] = r_df.iloc[0]['MEAN_PRICE'] # Mean price of day_0\n",
    "        curr_day['MAX_MEAN_PRICE'] = r_df[['MEAN_PRICE']].max().iat[0] # Max mean price from day_0..day_29\n",
    "        curr_day['MAX_MEAN_PRICE_RECOMMEND_DATE'] = r_df[['MEAN_PRICE']].idxmax().iat[0] # Max mean price date from day_0..day_29, recommended date by max value forecast method\n",
    "        curr_day['MAX_MEAN_RECOMMEND_DAY_PRICE'] = a_df[a_df.index == curr_day['MAX_MEAN_PRICE_RECOMMEND_DATE']]['PRICE'].item() # Actual price on the recommended date by max value forecast method\n",
    "        # With Prospect Theory\n",
    "        curr_day['PROSPECT_RECOMMEND_DATE'] = r_df[['PREDICTED']].idxmax().iat[0] # recommended date by prospect theory method\n",
    "        curr_day['PROSPECT_RECOMMEND_DAY_PRICE'] = a_df.loc[curr_day['PROSPECT_RECOMMEND_DATE']]['PRICE'].item() # Actual price on the recommended date \n",
    "        \n",
    "        curr_df = pd.DataFrame([curr_day])\n",
    "        res = pd.concat([res, curr_df])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(processedFilePath):\n",
    "    os.makedirs(processedFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperateForecastMethods(df):\n",
    "    # Mean value forecast method\n",
    "    mean_price_df = df[['DATE', 'ACTUAL_PRICE', 'ACTUAL_MAX', 'MAX_MEAN_PRICE_RECOMMEND_DATE', 'MAX_MEAN_RECOMMEND_DAY_PRICE']].copy()\n",
    "    mean_price_df.rename(columns={'MAX_MEAN_PRICE_RECOMMEND_DATE' : 'RECOMMEND_DATE', 'MAX_MEAN_RECOMMEND_DAY_PRICE' : 'RECOMMEND_DAY_PRICE'} , inplace=True)\n",
    "    # Prospect theory method\n",
    "    prospect_df = df[['DATE', 'ACTUAL_PRICE', 'ACTUAL_MAX', 'PROSPECT_RECOMMEND_DATE', 'PROSPECT_RECOMMEND_DAY_PRICE']].copy()\n",
    "    prospect_df.rename(columns={'PROSPECT_RECOMMEND_DATE' : 'RECOMMEND_DATE', 'PROSPECT_RECOMMEND_DAY_PRICE' : 'RECOMMEND_DAY_PRICE'} , inplace=True)\n",
    "    return mean_price_df, prospect_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- processed Day_2922.csv --\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "reduction operation 'argmax' not allowed for this dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-53577eed596d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Process files with error models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwith_error_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwithErrorModelFilePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactualPricesFilePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mwith_error_mean_price_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_error_prospect_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseperateForecastMethods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_error_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwith_error_mean_price_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessedFilePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'with_error_mean_price.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwith_error_prospect_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessedFilePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'with_error_prospect.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-8d2f8ac1150d>\u001b[0m in \u001b[0;36mprocessFile\u001b[0;34m(recommendationsPath, actualPath)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mcurr_day\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MAX_MEAN_RECOMMEND_DAY_PRICE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcurr_day\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MAX_MEAN_PRICE_RECOMMEND_DATE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PRICE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Actual price on the recommended date by max value forecast method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# With Prospect Theory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mcurr_day\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PROSPECT_RECOMMEND_DATE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PREDICTED'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# recommended date by prospect theory method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mcurr_day\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PROSPECT_RECOMMEND_DAY_PRICE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_day\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PROSPECT_RECOMMEND_DATE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PRICE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Actual price on the recommended date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/utf/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36midxmax\u001b[0;34m(self, axis, skipna)\u001b[0m\n\u001b[1;32m   8870\u001b[0m         \"\"\"\n\u001b[1;32m   8871\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8872\u001b[0;31m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnanops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanargmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8874\u001b[0m         \u001b[0;31m# indices will always be np.ndarray since axis is not None and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/utf/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mf_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nan\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 raise TypeError(\n\u001b[0;32m---> 67\u001b[0;31m                     \u001b[0;34mf\"reduction operation '{f_name}' not allowed for this dtype\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                 )\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: reduction operation 'argmax' not allowed for this dtype"
     ]
    }
   ],
   "source": [
    "# Process files with error models\n",
    "with_error_df = processFile(withErrorModelFilePath, actualPricesFilePath)\n",
    "with_error_mean_price_df, with_error_prospect_df = seperateForecastMethods(with_error_df)\n",
    "with_error_mean_price_df.to_csv(os.path.join(processedFilePath, 'with_error_mean_price.csv'), index=False)\n",
    "with_error_prospect_df.to_csv(os.path.join(processedFilePath, 'with_error_prospect.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process file without error models\n",
    "without_error_df = processFile(withoutErrorModelFilePath, actualPricesFilePath)\n",
    "without_error_mean_price_df, without_error_prospect_df = seperateForecastMethods(without_error_df)\n",
    "without_error_mean_price_df.to_csv(os.path.join(processedFilePath, 'without_error_mean_price.csv'), index=False)\n",
    "without_error_prospect_df.to_csv(os.path.join(processedFilePath, 'without_error_prospect.csv'), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_df - ['DATE', 'ACTUAL_PRICE', 'ACTUAL_MAX', 'RECOMMEND_DATE', 'RECOMMEND_DAY_PRICE']\n",
    "def computeMetrics(p_df):\n",
    "    ans = {}\n",
    "    \n",
    "    n = p_df.shape[0]\n",
    "    diff = 0\n",
    "    p_df['DATE'] = pd.to_datetime(p_df['DATE'])\n",
    "    p_df['RECOMMEND_DATE'] = pd.to_datetime(p_df['RECOMMEND_DATE'])\n",
    "\n",
    "    for i in range(n-1):\n",
    "        j = i + 1\n",
    "        diff += abs((p_df.iloc[i]['RECOMMEND_DATE'] - p_df.iloc[j]['RECOMMEND_DATE']).days)\n",
    "    \n",
    "    count = 0\n",
    "    threshold = 2\n",
    "    for i in range(n-1):\n",
    "        j = i + 1\n",
    "        if abs((p_df.iloc[i]['RECOMMEND_DATE'] - p_df.iloc[j]['RECOMMEND_DATE']).days) <= threshold:\n",
    "            count += 1\n",
    "    \n",
    "    ans['VOR'] = diff / (n-1)\n",
    "    ans['PCR'] = count*100 / (n-1)\n",
    "    ans['PAP'] = sum(p_df['ACTUAL_PRICE'] <= p_df['RECOMMEND_DAY_PRICE']) * 100 / n\n",
    "    ans['NG'] = sum(p_df['RECOMMEND_DAY_PRICE'] - p_df['ACTUAL_PRICE']) / n # Actual price of day 0\n",
    "    ans['RMSE_ORACLE'] = (sum((p_df['ACTUAL_MAX'] - p_df['RECOMMEND_DAY_PRICE']) ** 2) / n) ** 0.5  \n",
    "    ans['NG_ORACLE'] = sum(p_df['ACTUAL_MAX'] - p_df['ACTUAL_PRICE']) / n\n",
    "\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateMetrics(start_date, end_date):\n",
    "    data = {\n",
    "        'Model': [],\n",
    "        'Recommendation Method': [],\n",
    "        'Metric': [],\n",
    "        'Value': []\n",
    "    }\n",
    "\n",
    "    for fname in os.listdir(processedFilePath):\n",
    "        if 'netgain' in fname or os.path.isdir(os.path.join(processedFilePath, fname)):\n",
    "            continue\n",
    "        p_df = pd.read_csv(os.path.join(processedFilePath, fname))\n",
    "        p_df = p_df[(p_df['DATE'] >= start_date) & (p_df['DATE'] <= end_date)]\n",
    "        model = 'ERROR' if 'with_error' in fname else 'WITHOUT_ERROR'\n",
    "        recommendation_method = 'MAX_MEAN' if 'mean_price' in fname else 'PROSPECT'\n",
    "        metrics = computeMetrics(p_df)\n",
    "        data['Model'] += ([model]*len(metrics))\n",
    "        data['Recommendation Method'] += ([recommendation_method]*len(metrics))\n",
    "        data['Metric'] += (list(metrics.keys()))\n",
    "        data['Value'] += (list(metrics.values()))\n",
    "\n",
    "    metrics_df = pd.DataFrame(data)\n",
    "    # print(metrics_df['Metric'])\n",
    "    metrics_df = metrics_df.pivot(index='Metric', columns=['Model', 'Recommendation Method'], values='Value')\n",
    "    return metrics_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving computed metrics seasonal and yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Generating seasonal metrics for period 2014-09-01 to 2015-01-31 --\n",
      "-- Generating yearly metrics for period 2014-01-01 to 2014-12-31 --\n",
      "-- Generating seasonal metrics for period 2015-09-01 to 2016-01-31 --\n",
      "-- Generating yearly metrics for period 2015-01-01 to 2015-12-31 --\n",
      "-- Generating seasonal metrics for period 2016-09-01 to 2017-01-31 --\n",
      "-- Generating yearly metrics for period 2016-01-01 to 2016-12-31 --\n",
      "-- Generating seasonal metrics for period 2017-09-01 to 2018-01-31 --\n",
      "-- Generating yearly metrics for period 2017-01-01 to 2017-12-31 --\n",
      "-- Generating seasonal metrics for period 2018-09-01 to 2019-01-31 --\n",
      "-- Generating yearly metrics for period 2018-01-01 to 2018-12-31 --\n",
      "-- Generating seasonal metrics for period 2019-09-01 to 2020-01-31 --\n",
      "-- Generating yearly metrics for period 2019-01-01 to 2019-12-31 --\n",
      "-- Generating seasonal metrics for period 2020-09-01 to 2021-01-31 --\n",
      "-- Generating yearly metrics for period 2020-01-01 to 2020-12-31 --\n"
     ]
    }
   ],
   "source": [
    "for year in range(2014, 2021):\n",
    "    metricsPath = os.path.join(processedFilePath, 'metrics')\n",
    "    if not os.path.exists(metricsPath):\n",
    "        os.makedirs(metricsPath)\n",
    "    start_date, end_date = f'{year}-09-01', f'{year+1}-01-31'\n",
    "    print(f\"-- Generating seasonal metrics for period {start_date} to {end_date} --\")\n",
    "    seasonal_df = generateMetrics(start_date, end_date)\n",
    "    start_date, end_date = f'{year}-01-01', f'{year}-12-31'\n",
    "    print(f\"-- Generating yearly metrics for period {start_date} to {end_date} --\")\n",
    "    yearly_df = generateMetrics(start_date, end_date)\n",
    "    seasonal_df.to_csv(os.path.join(metricsPath, f'metrics_seasonal_09_{year}_01_{year+1}.csv'))\n",
    "    yearly_df.to_csv(os.path.join(metricsPath, f'metrics_yearly_{year}.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving aggregated metrics for entire duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date, end_date = f'2014-01-01', f'2020-12-31'\n",
    "final_df = generateMetrics(start_date, end_date)\n",
    "final_df.to_csv(os.path.join(os.path.join(processedFilePath, 'metrics'), f'metrics_2014_2020.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting and saving plots seasonal and yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotActualForecast(start_date, end_date, actualPricesFilePath, recommendationPath):\n",
    "    base_date = datetime.strptime(\"2006-01-01\", \"%Y-%m-%d\")\n",
    "    start_idx = (datetime.strptime(start_date, \"%Y-%m-%d\") - base_date).days\n",
    "    end_idx = (datetime.strptime(end_date, \"%Y-%m-%d\") - base_date).days\n",
    "    actual_df = pd.read_csv(actualPricesFilePath, index_col=['DATE'])\n",
    "    final_df = pd.DataFrame()\n",
    "    for idx in range(start_idx, end_idx, 30):\n",
    "        p_df = pd.read_csv(os.path.join(recommendationPath, f\"Day_{idx}.csv\"), index_col=['DATE'])\n",
    "        t_df = pd.merge(p_df, actual_df, left_index=True, right_index=True, how='inner')\n",
    "        final_df = pd.concat([final_df, t_df])\n",
    "    final_df = final_df[final_df.index <= end_date]\n",
    "    final_df.index = pd.to_datetime(final_df.index)\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    ax.plot(final_df.index, final_df['PRICE'], label='Actual', color='green')\n",
    "    ax.plot(final_df.index, final_df['MEAN_PRICE'], label='Forecasted', color='red')\n",
    "    month_locater = mdates.MonthLocator()\n",
    "    month_formatter = mdates.DateFormatter(\"%b\")\n",
    "    ax.xaxis.set_major_locator(month_locater)\n",
    "    ax.xaxis.set_major_formatter(month_formatter)\n",
    "    ax.set_xlabel(f'Months')\n",
    "    ax.set_ylabel('Price(in Rs)')\n",
    "    ax.set_title(f'Soyabean prices from {start_date} to {end_date}')\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(45)\n",
    "    ax.legend()\n",
    "    return fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving yearly and seasonal plots with error models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2014, 2021):\n",
    "    plotsPath = os.path.join(processedFilePath, 'plots')\n",
    "    if not os.path.exists(plotsPath):\n",
    "        os.makedirs(plotsPath)\n",
    "    start_date, end_date = f'{year}-09-01', f'{year+1}-01-31'\n",
    "    fig = plotActualForecast(start_date, end_date, actualPricesFilePath, withErrorModelFilePath)    \n",
    "    fig.savefig(os.path.join(plotsPath, f'plot_seasonal_09_{year}_01_{year+1}.png'), facecolor='w')\n",
    "    plt.close(fig)\n",
    "    start_date, end_date = f'{year}-01-01', f'{year}-12-31'\n",
    "    fig = plotActualForecast(start_date, end_date, actualPricesFilePath, withErrorModelFilePath)\n",
    "    fig.savefig(os.path.join(plotsPath, f'plot_yearly_{year}.png'), facecolor='w')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotsPath = os.path.join(processedFilePath, 'plots')\n",
    "# if not os.path.exists(plotsPath):\n",
    "#     os.makedirs(plotsPath)\n",
    "# start_date, end_date = f'2014-01-01', f'2014-12-31'\n",
    "# fig = plotActualForecast(start_date, end_date, actualPricesFilePath, withErrorModelFilePath)\n",
    "# fig.savefig(os.path.join(plotsPath, f'plot_yearly_with_error_2014_2020.png'), facecolor='w')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving yearly and seasonal plots without error models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2014, 2021):\n",
    "    plotsPath = os.path.join(processedFilePath, 'plots')\n",
    "    if not os.path.exists(plotsPath):\n",
    "        os.makedirs(plotsPath)\n",
    "    start_date, end_date = f'{year}-09-01', f'{year+1}-01-31'\n",
    "    fig = plotActualForecast(start_date, end_date, actualPricesFilePath, withoutErrorModelFilePath)    \n",
    "    fig.savefig(os.path.join(plotsPath, f'plot_seasonal_without_error_09_{year}_01_{year+1}.png'), facecolor='w')\n",
    "    plt.close(fig)\n",
    "    start_date, end_date = f'{year}-01-01', f'{year}-12-31'\n",
    "    fig = plotActualForecast(start_date, end_date, actualPricesFilePath, withoutErrorModelFilePath)\n",
    "    fig.savefig(os.path.join(plotsPath, f'plot_yearly_without_error_{year}.png'), facecolor='w')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate files with netgain computed on a daily basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in os.listdir(processedFilePath):\n",
    "    if 'with' not in fname:\n",
    "        continue\n",
    "    p_df = pd.read_csv(os.path.join(processedFilePath, fname))\n",
    "    p_df['NET_GAIN'] = p_df['RECOMMEND_DAY_PRICE'] - p_df['ACTUAL_PRICE']\n",
    "    p_df['NET_GAIN_ORACLE'] = p_df['ACTUAL_MAX'] - p_df['ACTUAL_PRICE']\n",
    "    p_df.to_csv(os.path.join(processedFilePath, f\"netgain_{fname}\"), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting netgain on a daily basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotNetGain(start_date, end_date):\n",
    "    start_dt = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_dt = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    for fname in os.listdir(processedFilePath):\n",
    "        if 'netgain' not in fname:\n",
    "            continue\n",
    "        p_df = pd.read_csv(os.path.join(processedFilePath, fname))\n",
    "        p_df = p_df[(p_df['DATE'] >= start_date) & (p_df['DATE'] <= end_date)]\n",
    "        model = 'with_error' if 'with_error' in fname else 'without_error'\n",
    "        recommendation_method = 'max_mean' if 'mean_price' in fname else 'prospect'\n",
    "        fig, ax = plt.subplots(figsize=(15, 8))\n",
    "        ax.plot(p_df.index, p_df['NET_GAIN'], label='Net Gain', color='green')\n",
    "        ax.plot(p_df.index, p_df['NET_GAIN_ORACLE'], label='Net Gain Oracle', color='red')\n",
    "        month_locater = mdates.MonthLocator()\n",
    "        month_formatter = mdates.DateFormatter(\"%b\")\n",
    "        ax.xaxis.set_major_locator(month_locater)\n",
    "        ax.xaxis.set_major_formatter(month_formatter)\n",
    "        ax.set_xlabel(f'Months')\n",
    "        ax.set_ylabel('Price(in Rs)')\n",
    "        ax.set_title(f'Net Gain and Net Gain Oracle from {start_date} to {end_date}')\n",
    "        for tick in ax.get_xticklabels():\n",
    "            tick.set_rotation(45)\n",
    "        ax.legend()\n",
    "        fig.savefig(os.path.join(plotsPath, f'netgain_{model}_{recommendation_method}_plot_{start_dt.month}_{start_dt.year}_{end_dt.month}_{end_dt.year}.png'), facecolor='w')\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2014, 2021):\n",
    "    start_date, end_date = f'{year}-09-01', f'{year+1}-01-31'\n",
    "    plotNetGain(start_date, end_date)\n",
    "    start_date, end_date = f'{year}-01-01', f'{year}-12-31'\n",
    "    plotNetGain(start_date, end_date)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE over interval:\n",
    "def rmse30DayWindow(df):\n",
    "    mse = (df[\"PRICE\"] - df[\"MEAN_PRICE\"]) ** 2\n",
    "    rmse = (mse.mean()) ** .5\n",
    "    return rmse\n",
    "\n",
    "def RMSE(df):\n",
    "    l30, l1, lnormalized = [], [], []\n",
    "    for i in range(0, len(df), 30):\n",
    "        x30 = rmse30DayWindow(df[i:i + 30])\n",
    "        l30.append(x30)\n",
    "    return np.mean(l30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(start_date, end_date, actualPricesFilePath, recommendationPath):\n",
    "    base_date = datetime.strptime(\"2006-01-01\", \"%Y-%m-%d\")\n",
    "    start_idx = (datetime.strptime(start_date, \"%Y-%m-%d\") - base_date).days\n",
    "    end_idx = (datetime.strptime(end_date, \"%Y-%m-%d\") - base_date).days\n",
    "    actual_df = pd.read_csv(actualPricesFilePath, index_col=['DATE'])\n",
    "    final_df = pd.DataFrame()\n",
    "    for idx in range(start_idx, end_idx, 30):\n",
    "        p_df = pd.read_csv(os.path.join(recommendationPath, f\"Day_{idx}.csv\"), index_col=['DATE'])\n",
    "        t_df = pd.merge(p_df, actual_df, left_index=True, right_index=True, how='inner')\n",
    "        final_df = pd.concat([final_df, t_df])\n",
    "    final_df = final_df[final_df.index <= end_date]\n",
    "    n_df = final_df[['PRICE', 'MEAN_PRICE']].copy()\n",
    "    rmse = RMSE(n_df)\n",
    "    daily_rmse = ((n_df['PRICE'] - n_df['MEAN_PRICE']) ** 2).mean() ** .5\n",
    "    return rmse, daily_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_daily_rmse(start_date, end_date, actualPricesFilePath, recommendationPath):\n",
    "    base_date = datetime.strptime(\"2006-01-01\", \"%Y-%m-%d\")\n",
    "    start_idx = (datetime.strptime(start_date, \"%Y-%m-%d\") - base_date).days\n",
    "    end_idx = (datetime.strptime(end_date, \"%Y-%m-%d\") - base_date).days\n",
    "    actual_df = pd.read_csv(actualPricesFilePath, index_col=['DATE'])\n",
    "    all_rmse = []\n",
    "    for idx in range(start_idx, end_idx):\n",
    "        p_df = pd.read_csv(os.path.join(recommendationPath, f\"Day_{idx}.csv\"), index_col=['DATE'])\n",
    "        t_df = pd.merge(p_df, actual_df, left_index=True, right_index=True, how='inner')\n",
    "        t_rmse = ((t_df['PRICE'] - t_df['MEAN_PRICE']) ** 2).mean() ** .5\n",
    "        all_rmse.append(t_rmse)\n",
    "    return sum(all_rmse)/len(all_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Type': [], 'Duration': [], 'Year': [], 'Rolling RMSE': [], 'Daily RMSE': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"---- With Error Models ----\")\n",
    "for year in range(2014, 2021):\n",
    "    plotsPath = os.path.join(processedFilePath, 'plots')\n",
    "    if not os.path.exists(plotsPath):\n",
    "        os.makedirs(plotsPath)\n",
    "    start_date, end_date = f'{year}-09-01', f'{year+1}-01-31'\n",
    "    rmse, daily_rmse = compute_rmse(start_date, end_date, actualPricesFilePath, withErrorModelFilePath)\n",
    "\n",
    "    data['Type'].append('Error')\n",
    "    data['Duration'].append('Seasonal')\n",
    "    data['Year'].append(year)\n",
    "    data['Rolling RMSE'].append(rmse)\n",
    "    data['Daily RMSE'].append(daily_rmse)\n",
    "    # print(f\"Seasonal: Year: {year}, Rolling RMSE: {rmse}, Daily RMSE: {daily_rmse}\")\n",
    "    \n",
    "    start_date, end_date = f'{year}-01-01', f'{year}-12-31'\n",
    "    rmse, daily_rmse = compute_rmse(start_date, end_date, actualPricesFilePath, withErrorModelFilePath)    \n",
    "    # print(f\"Yearly: Year: {year}, Rolling RMSE: {rmse}, Daily RMSE: {daily_rmse}\")\n",
    "    \n",
    "    data['Type'].append('Error')\n",
    "    data['Duration'].append('Yearly')\n",
    "    data['Year'].append(year)\n",
    "    data['Rolling RMSE'].append(rmse)\n",
    "    data['Daily RMSE'].append(daily_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"---- Without Error Models ----\")\n",
    "for year in range(2014, 2021):\n",
    "    plotsPath = os.path.join(processedFilePath, 'plots')\n",
    "    if not os.path.exists(plotsPath):\n",
    "        os.makedirs(plotsPath)\n",
    "    start_date, end_date = f'{year}-09-01', f'{year+1}-01-31'\n",
    "    # print(withoutErrorModelFilePath)\n",
    "    rmse, daily_rmse = compute_rmse(start_date, end_date, actualPricesFilePath, withoutErrorModelFilePath)    \n",
    "    # print(f\"Seasonal: Year: {year}, Rolling RMSE: {rmse}, Daily RMSE: {daily_rmse}\")\n",
    "\n",
    "    data['Type'].append('Without Error')\n",
    "    data['Duration'].append('Seasonal')\n",
    "    data['Year'].append(year)\n",
    "    data['Rolling RMSE'].append(rmse)\n",
    "    data['Daily RMSE'].append(daily_rmse)\n",
    "\n",
    "\n",
    "    start_date, end_date = f'{year}-01-01', f'{year}-12-31'\n",
    "    rmse, daily_rmse = compute_rmse(start_date, end_date, actualPricesFilePath, withoutErrorModelFilePath)    \n",
    "    # print(f\"Yearly: Year: {year}, Rolling RMSE: {rmse}, Daily RMSE: {daily_rmse}\")\n",
    "\n",
    "    data['Type'].append('Without Error')\n",
    "    data['Duration'].append('Yearly')\n",
    "    data['Year'].append(year)\n",
    "    data['Rolling RMSE'].append(rmse)\n",
    "    data['Daily RMSE'].append(daily_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling RMSE: \n",
      "138.23572132962667 149.14806085653055\n"
     ]
    }
   ],
   "source": [
    "start_date, end_date = f'2014-01-01', f'2020-12-31'\n",
    "rmse_with, _ = compute_rmse(start_date, end_date, actualPricesFilePath, withErrorModelFilePath)  \n",
    "rmse_without, _ = compute_rmse(start_date, end_date, actualPricesFilePath, withoutErrorModelFilePath)  \n",
    "print(\"Rolling RMSE: \")\n",
    "print(rmse_with, rmse_without)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily RMSE: \n",
      "138.22133132902093 146.30596213216836\n"
     ]
    }
   ],
   "source": [
    "start_date, end_date = f'2014-01-01', f'2020-12-31'\n",
    "rmse_with = compute_daily_rmse(start_date, end_date, actualPricesFilePath, withErrorModelFilePath)  \n",
    "rmse_without = compute_daily_rmse(start_date, end_date, actualPricesFilePath, withoutErrorModelFilePath)  \n",
    "print(\"Daily RMSE: \")\n",
    "print(rmse_with, rmse_without)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Rolling RMSE</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Daily RMSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Error</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Without Error</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Error</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Without Error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duration</th>\n",
       "      <th>Seasonal</th>\n",
       "      <th>Yearly</th>\n",
       "      <th>Seasonal</th>\n",
       "      <th>Yearly</th>\n",
       "      <th>Seasonal</th>\n",
       "      <th>Yearly</th>\n",
       "      <th>Seasonal</th>\n",
       "      <th>Yearly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>138.349789</td>\n",
       "      <td>163.851176</td>\n",
       "      <td>145.615373</td>\n",
       "      <td>182.784914</td>\n",
       "      <td>168.122926</td>\n",
       "      <td>190.987220</td>\n",
       "      <td>164.757964</td>\n",
       "      <td>203.224358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>146.514513</td>\n",
       "      <td>184.257435</td>\n",
       "      <td>147.845980</td>\n",
       "      <td>176.573554</td>\n",
       "      <td>175.966819</td>\n",
       "      <td>204.064849</td>\n",
       "      <td>181.982420</td>\n",
       "      <td>195.909729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>82.399535</td>\n",
       "      <td>118.797953</td>\n",
       "      <td>87.983493</td>\n",
       "      <td>133.216169</td>\n",
       "      <td>98.927305</td>\n",
       "      <td>130.121424</td>\n",
       "      <td>106.279565</td>\n",
       "      <td>146.457629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>137.246321</td>\n",
       "      <td>73.135883</td>\n",
       "      <td>151.353176</td>\n",
       "      <td>83.353782</td>\n",
       "      <td>110.086259</td>\n",
       "      <td>79.861756</td>\n",
       "      <td>124.952693</td>\n",
       "      <td>88.091838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>157.450510</td>\n",
       "      <td>132.801100</td>\n",
       "      <td>168.220568</td>\n",
       "      <td>142.367504</td>\n",
       "      <td>163.441247</td>\n",
       "      <td>145.585735</td>\n",
       "      <td>176.800905</td>\n",
       "      <td>156.033963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Rolling RMSE                                        Daily RMSE  \\\n",
       "Type            Error             Without Error                   Error   \n",
       "Duration     Seasonal      Yearly      Seasonal      Yearly    Seasonal   \n",
       "Year                                                                      \n",
       "2014       138.349789  163.851176    145.615373  182.784914  168.122926   \n",
       "2015       146.514513  184.257435    147.845980  176.573554  175.966819   \n",
       "2016        82.399535  118.797953     87.983493  133.216169   98.927305   \n",
       "2017       137.246321   73.135883    151.353176   83.353782  110.086259   \n",
       "2018       157.450510  132.801100    168.220568  142.367504  163.441247   \n",
       "\n",
       "                                                \n",
       "Type                 Without Error              \n",
       "Duration      Yearly      Seasonal      Yearly  \n",
       "Year                                            \n",
       "2014      190.987220    164.757964  203.224358  \n",
       "2015      204.064849    181.982420  195.909729  \n",
       "2016      130.121424    106.279565  146.457629  \n",
       "2017       79.861756    124.952693   88.091838  \n",
       "2018      145.585735    176.800905  156.033963  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_df = pd.DataFrame(data)\n",
    "rmse_df = pd.pivot(rmse_df, index='Year', columns=['Type', 'Duration'], values=['Rolling RMSE', 'Daily RMSE'])\n",
    "\n",
    "# print(processedFilePath)\n",
    "rmse_df.to_csv(os.path.join(os.path.join(processedFilePath, 'metrics'), f'rmse_2014_2020.csv'))\n",
    "rmse_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7db9c00ba57316717bbc6026097185eeb57bfdc497905db08596415667c38f82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
