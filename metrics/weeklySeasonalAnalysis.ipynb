{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = 'Rajasthan'\n",
    "mandi = 'Kota'\n",
    "exp_no = 6\n",
    "retrainFreq = 15\n",
    "actualPricesFilePath = os.path.join(f'../Data/PlottingData/SOYABEAN/ARIMA_Interpolated_Data/', f'{state.upper()}_{mandi.upper()}_Price.csv')\n",
    "recommendationFilePath = f'./EXP{exp_no}_CYCLIC_{state.upper()}_{mandi.upper()}/Recommendations/RetrainFreq{retrainFreq}Day/'\n",
    "withErrorModelFilePath = os.path.join(recommendationFilePath, 'WithErrorModels')\n",
    "withoutErrorModelFilePath = os.path.join(recommendationFilePath, 'WithoutErrorModels')\n",
    "processedFilePath = os.path.join(recommendationFilePath, 'Processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renameFiles(path, pattern, rpattern):\n",
    "    comp = re.compile(pattern)\n",
    "    for f in os.listdir(path):\n",
    "        full_path = os.path.join(path, f)\n",
    "        if os.path.isfile(full_path):\n",
    "            match = comp.search(f)\n",
    "            if not match :\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                new_name = match.expand(rpattern)\n",
    "                new_name = os.path.join(path, new_name)\n",
    "            except re.error:\n",
    "                continue\n",
    "        \n",
    "            if os.path.isfile(new_name):\n",
    "                print('%s -> %s skipped' % (f, new_name))\n",
    "            else:\n",
    "                os.rename(full_path, new_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern, rpattern = r'^recommend_with_errormodel_(\\d{0,4}).csv$', r\"Day_\\1.csv\"\n",
    "renameFiles(withErrorModelFilePath, pattern, rpattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern, rpattern = r'^recommend_without_errormodel_(\\d{0,4}).csv$', r\"Day_\\1.csv\"\n",
    "renameFiles(withoutErrorModelFilePath, pattern, rpattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processFile(recommendationsPath, actualPath):\n",
    "    actual_df = pd.read_csv(actualPath, index_col=['DATE'])\n",
    "    res = pd.DataFrame()\n",
    "    all_files = os.listdir(recommendationsPath)\n",
    "    all_files.sort()\n",
    "    for fileName in all_files:\n",
    "        path = os.path.join(recommendationsPath, fileName)\n",
    "        r_df = pd.read_csv(path, index_col=['DATE'])\n",
    "        a_df = actual_df[actual_df.index.isin(r_df.index)]\n",
    "        \n",
    "        curr_day = {}\n",
    "        curr_day['DATE'] = a_df.index[0]\n",
    "        curr_day['ACTUAL_PRICE'] = a_df.iloc[0]['PRICE'] # Actual price of day_0\n",
    "        curr_day['ACTUAL_MAX'] = a_df[['PRICE']].max().iat[0]\n",
    "\n",
    "        # Without Prospect Theory\n",
    "        curr_day['MEAN_PRICE'] = r_df.iloc[0]['MEAN_PRICE'] # Mean price of day_0\n",
    "        curr_day['MAX_MEAN_PRICE'] = r_df[['MEAN_PRICE']].max().iat[0] # Max mean price from day_0..day_29\n",
    "        curr_day['MAX_MEAN_PRICE_RECOMMEND_DATE'] = r_df[['MEAN_PRICE']].idxmax().iat[0] # Max mean price date from day_0..day_29, recommended date by max value forecast method\n",
    "        curr_day['MAX_MEAN_RECOMMEND_DAY_PRICE'] = a_df[a_df.index == curr_day['MAX_MEAN_PRICE_RECOMMEND_DATE']]['PRICE'].item() # Actual price on the recommended date by max value forecast method\n",
    "        # With Prospect Theory\n",
    "        curr_day['PROSPECT_RECOMMEND_DATE'] = r_df[['PREDICTED']].idxmax().iat[0] # recommended date by prospect theory method\n",
    "        curr_day['PROSPECT_RECOMMEND_DAY_PRICE'] = a_df.loc[curr_day['PROSPECT_RECOMMEND_DATE']]['PRICE'].item() # Actual price on the recommended date \n",
    "        \n",
    "        curr_df = pd.DataFrame([curr_day])\n",
    "        res = pd.concat([res, curr_df])\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(processedFilePath):\n",
    "    os.makedirs(processedFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperateForecastMethods(df):\n",
    "    # Mean value forecast method\n",
    "    mean_price_df = df[['DATE', 'ACTUAL_PRICE', 'ACTUAL_MAX', 'MAX_MEAN_PRICE_RECOMMEND_DATE', 'MAX_MEAN_RECOMMEND_DAY_PRICE']].copy()\n",
    "    mean_price_df.rename(columns={'MAX_MEAN_PRICE_RECOMMEND_DATE' : 'RECOMMEND_DATE', 'MAX_MEAN_RECOMMEND_DAY_PRICE' : 'RECOMMEND_DAY_PRICE'} , inplace=True)\n",
    "    # Prospect theory method\n",
    "    prospect_df = df[['DATE', 'ACTUAL_PRICE', 'ACTUAL_MAX', 'PROSPECT_RECOMMEND_DATE', 'PROSPECT_RECOMMEND_DAY_PRICE']].copy()\n",
    "    prospect_df.rename(columns={'PROSPECT_RECOMMEND_DATE' : 'RECOMMEND_DATE', 'PROSPECT_RECOMMEND_DAY_PRICE' : 'RECOMMEND_DAY_PRICE'} , inplace=True)\n",
    "    return mean_price_df, prospect_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process files with error models\n",
    "with_error_df = processFile(withErrorModelFilePath, actualPricesFilePath)\n",
    "with_error_mean_price_df, with_error_prospect_df = seperateForecastMethods(with_error_df)\n",
    "with_error_mean_price_df.to_csv(os.path.join(processedFilePath, 'with_error_mean_price.csv'), index=False)\n",
    "with_error_prospect_df.to_csv(os.path.join(processedFilePath, 'with_error_prospect.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process file without error models\n",
    "without_error_df = processFile(withoutErrorModelFilePath, actualPricesFilePath)\n",
    "without_error_mean_price_df, without_error_prospect_df = seperateForecastMethods(without_error_df)\n",
    "without_error_mean_price_df.to_csv(os.path.join(processedFilePath, 'without_error_mean_price.csv'), index=False)\n",
    "without_error_prospect_df.to_csv(os.path.join(processedFilePath, 'without_error_prospect.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_df - ['DATE', 'ACTUAL_PRICE', 'ACTUAL_MAX', 'RECOMMEND_DATE', 'RECOMMEND_DAY_PRICE']\n",
    "def computeMetrics(p_df):\n",
    "    ans = {}\n",
    "    \n",
    "    n = p_df.shape[0]\n",
    "    diff = 0\n",
    "    p_df['DATE'] = pd.to_datetime(p_df['DATE'])\n",
    "    p_df['RECOMMEND_DATE'] = pd.to_datetime(p_df['RECOMMEND_DATE'])\n",
    "\n",
    "    for i in range(n-1):\n",
    "        j = i + 1\n",
    "        diff += abs((p_df.iloc[i]['RECOMMEND_DATE'] - p_df.iloc[j]['RECOMMEND_DATE']).days)\n",
    "    \n",
    "    count = 0\n",
    "    threshold = 2\n",
    "    for i in range(n-1):\n",
    "        j = i + 1\n",
    "        if abs((p_df.iloc[i]['RECOMMEND_DATE'] - p_df.iloc[j]['RECOMMEND_DATE']).days) <= threshold:\n",
    "            count += 1\n",
    "    \n",
    "    ans['VOR'] = diff / (n-1)\n",
    "    ans['PCR'] = count*100 / (n-1)\n",
    "    ans['PAP'] = sum(p_df['ACTUAL_PRICE'] <= p_df['RECOMMEND_DAY_PRICE']) * 100 / n\n",
    "    ans['NG'] = sum(p_df['RECOMMEND_DAY_PRICE'] - p_df['ACTUAL_PRICE']) / n # Actual price of day 0\n",
    "    ans['RMSE_ORACLE'] = (sum((p_df['ACTUAL_MAX'] - p_df['RECOMMEND_DAY_PRICE']) ** 2) / n) ** 0.5  \n",
    "    ans['NG_ORACLE'] = sum(p_df['ACTUAL_MAX'] - p_df['ACTUAL_PRICE']) / n\n",
    "\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateMetrics(start_date, end_date):\n",
    "    data = {\n",
    "        'Model': [],\n",
    "        'Recommendation Method': [],\n",
    "        'Metric': [],\n",
    "        'Value': []\n",
    "    }\n",
    "\n",
    "    for fname in os.listdir(processedFilePath):\n",
    "        if 'netgain' in fname or os.path.isdir(os.path.join(processedFilePath, fname)):\n",
    "            continue\n",
    "        p_df = pd.read_csv(os.path.join(processedFilePath, fname))\n",
    "        p_df = p_df[(p_df['DATE'] >= start_date) & (p_df['DATE'] <= end_date)]\n",
    "        model = 'ERROR' if 'with_error' in fname else 'WITHOUT_ERROR'\n",
    "        recommendation_method = 'MAX_MEAN' if 'mean_price' in fname else 'PROSPECT'\n",
    "        metrics = computeMetrics(p_df)\n",
    "        data['Model'] += ([model]*len(metrics))\n",
    "        data['Recommendation Method'] += ([recommendation_method]*len(metrics))\n",
    "        data['Metric'] += (list(metrics.keys()))\n",
    "        data['Value'] += (list(metrics.values()))\n",
    "\n",
    "    metrics_df = pd.DataFrame(data)\n",
    "    # print(metrics_df['Metric'])\n",
    "    metrics_df = metrics_df.pivot(index='Metric', columns=['Model', 'Recommendation Method'], values='Value')\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving computed metrics seasonal and yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2014, 2021):\n",
    "    metricsPath = os.path.join(processedFilePath, 'metrics')\n",
    "    if not os.path.exists(metricsPath):\n",
    "        os.makedirs(metricsPath)\n",
    "    start_date, end_date = f'{year}-09-01', f'{year+1}-01-31'\n",
    "    seasonal_df = generateMetrics(start_date, end_date)\n",
    "    start_date, end_date = f'{year}-01-01', f'{year}-12-31'\n",
    "    yearly_df = generateMetrics(start_date, end_date)\n",
    "    seasonal_df.to_csv(os.path.join(metricsPath, f'metrics_seasonal_09_{year}_01_{year+1}.csv'))\n",
    "    yearly_df.to_csv(os.path.join(metricsPath, f'metrics_yearly_{year}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date, end_date = f'2014-01-01', f'2020-12-31'\n",
    "final_df = generateMetrics(start_date, end_date)\n",
    "final_df.to_csv(os.path.join(os.path.join(processedFilePath, 'metrics'), f'metrics_2014_2020.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./EXP24_RAJASTHAN_BHAWANI/Recommendations/RetrainFreq15Day/Processed/metrics\n"
     ]
    }
   ],
   "source": [
    "print(metricsPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting and saving plots seasonal and yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotActualForecast(start_date, end_date, actualPricesFilePath, recommendationPath):\n",
    "    base_date = datetime.strptime(\"2006-01-01\", \"%Y-%m-%d\")\n",
    "    start_idx = (datetime.strptime(start_date, \"%Y-%m-%d\") - base_date).days\n",
    "    end_idx = (datetime.strptime(end_date, \"%Y-%m-%d\") - base_date).days\n",
    "    actual_df = pd.read_csv(actualPricesFilePath, index_col=['DATE'])\n",
    "    actual_df.index = pd.to_datetime(actual_df.index)\n",
    "    final_df = pd.DataFrame()\n",
    "    for idx in range(start_idx, end_idx, 84):\n",
    "        p_df = pd.read_csv(os.path.join(recommendationPath, f\"Day_{idx}.csv\"), index_col=['DATE'])\n",
    "        p_df.index = pd.to_datetime(p_df.index)\n",
    "        for dt in p_df.index:\n",
    "            p_df.loc[dt, 'PRICE'] = actual_df.loc[dt:dt+timedelta(days=7), 'PRICE'].mean()\n",
    "        final_df = pd.concat([ final_df, p_df[['PRICE', 'MEAN_PRICE']] ])\n",
    "    final_df = final_df[final_df.index <= pd.to_datetime(end_date)]\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    ax.plot(final_df.index, final_df['PRICE'], label='Actual', color='green')\n",
    "    ax.plot(final_df.index, final_df['MEAN_PRICE'], label='Forecasted', color='red')\n",
    "    ax.vlines(x=pd.date_range(start=datetime.strptime(start_date, \"%Y-%m-%d\"), end=datetime.strptime(end_date, \"%Y-%m-%d\"), freq='84D'), ymin = min(final_df['MEAN_PRICE'].min(), final_df['PRICE'].min()) - 50, ymax = max(final_df['MEAN_PRICE'].max(), final_df['PRICE'].max()) + 50, colors='purple', ls='--', lw=2)\n",
    "    # day_locater = mdates.DayLocator(interval=84)\n",
    "    # day_formatter = mdates.DateFormatter(\"%b\")\n",
    "    # ax.xaxis.set_major_locator(day_locater)\n",
    "    # ax.xaxis.set_major_formatter(month_formatter)\n",
    "    ax.set_xlabel(f'Years')\n",
    "    ax.set_ylabel('Price(in Rs)')\n",
    "    ax.set_title(f'Soyabean prices from {start_date} to {end_date}')\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(45)\n",
    "    ax.legend()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './EXP3_CYCLIC_RAJASTHAN_KOTA/Recommendations/RetrainFreq15Day/WithErrorModels/Day_3342.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-ce0cc1bc49c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'2014-01-01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'2021-01-31'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplotActualForecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactualPricesFilePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwithErrorModelFilePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-b949a0adc29a>\u001b[0m in \u001b[0;36mplotActualForecast\u001b[0;34m(start_date, end_date, actualPricesFilePath, recommendationPath)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfinal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m84\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommendationPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Day_{idx}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DATE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mp_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    648\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './EXP3_CYCLIC_RAJASTHAN_KOTA/Recommendations/RetrainFreq15Day/WithErrorModels/Day_3342.csv'"
     ]
    }
   ],
   "source": [
    "start_date, end_date = f'2014-01-01', f'2021-01-31'\n",
    "fig = plotActualForecast(start_date, end_date, actualPricesFilePath, withErrorModelFilePath)\n",
    "print(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2014, 2021):\n",
    "    plotsPath = os.path.join(processedFilePath, 'plots')\n",
    "    if not os.path.exists(plotsPath):\n",
    "        os.makedirs(plotsPath)\n",
    "    start_date, end_date = f'{year}-09-01', f'{year+1}-01-31'\n",
    "    fig = plotActualForecast(start_date, end_date, actualPricesFilePath, withErrorModelFilePath)    \n",
    "    fig.savefig(os.path.join(plotsPath, f'plot_seasonal_09_{year}_01_{year+1}.png'), facecolor='w')\n",
    "    plt.close(fig)\n",
    "    start_date, end_date = f'{year}-01-01', f'{year}-12-31'\n",
    "    fig = plotActualForecast(start_date, end_date, actualPricesFilePath, withErrorModelFilePath)\n",
    "    fig.savefig(os.path.join(plotsPath, f'plot_yearly_{year}.png'), facecolor='w')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2014, 2021):\n",
    "    plotsPath = os.path.join(processedFilePath, 'plots')\n",
    "    if not os.path.exists(plotsPath):\n",
    "        os.makedirs(plotsPath)\n",
    "    start_date, end_date = f'{year}-09-01', f'{year+1}-01-31'\n",
    "    fig = plotActualForecast(start_date, end_date, actualPricesFilePath, withoutErrorModelFilePath)    \n",
    "    fig.savefig(os.path.join(plotsPath, f'plot_seasonal_without_error_09_{year}_01_{year+1}.png'), facecolor='w')\n",
    "    plt.close(fig)\n",
    "    start_date, end_date = f'{year}-01-01', f'{year}-12-31'\n",
    "    fig = plotActualForecast(start_date, end_date, actualPricesFilePath, withoutErrorModelFilePath)\n",
    "    fig.savefig(os.path.join(plotsPath, f'plot_yearly_without_error_{year}.png'), facecolor='w')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate files with netgain computed on a daily basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in os.listdir(processedFilePath):\n",
    "    if 'with' not in fname:\n",
    "        continue\n",
    "    p_df = pd.read_csv(os.path.join(processedFilePath, fname))\n",
    "    p_df['NET_GAIN'] = p_df['RECOMMEND_DAY_PRICE'] - p_df['ACTUAL_PRICE']\n",
    "    p_df['NET_GAIN_ORACLE'] = p_df['ACTUAL_MAX'] - p_df['ACTUAL_PRICE']\n",
    "    p_df.to_csv(os.path.join(processedFilePath, f\"netgain_{fname}\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting netgain on a daily basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotNetGain(start_date, end_date):\n",
    "    start_dt = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_dt = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    for fname in os.listdir(processedFilePath):\n",
    "        if 'netgain' not in fname:\n",
    "            continue\n",
    "        p_df = pd.read_csv(os.path.join(processedFilePath, fname))\n",
    "        p_df = p_df[(p_df['DATE'] >= start_date) & (p_df['DATE'] <= end_date)]\n",
    "        model = 'with_error' if 'with_error' in fname else 'without_error'\n",
    "        recommendation_method = 'max_mean' if 'mean_price' in fname else 'prospect'\n",
    "        fig, ax = plt.subplots(figsize=(15, 8))\n",
    "        ax.plot(p_df.index, p_df['NET_GAIN'], label='Net Gain', color='green')\n",
    "        ax.plot(p_df.index, p_df['NET_GAIN_ORACLE'], label='Net Gain Oracle', color='red')\n",
    "        month_locater = mdates.MonthLocator()\n",
    "        month_formatter = mdates.DateFormatter(\"%b\")\n",
    "        ax.xaxis.set_major_locator(month_locater)\n",
    "        ax.xaxis.set_major_formatter(month_formatter)\n",
    "        ax.set_xlabel(f'Months')\n",
    "        ax.set_ylabel('Price(in Rs)')\n",
    "        ax.set_title(f'Net Gain and Net Gain Oracle from {start_date} to {end_date}')\n",
    "        for tick in ax.get_xticklabels():\n",
    "            tick.set_rotation(45)\n",
    "        ax.legend()\n",
    "        fig.savefig(os.path.join(plotsPath, f'netgain_{model}_{recommendation_method}_plot_{start_dt.month}_{start_dt.year}_{end_dt.month}_{end_dt.year}.png'), facecolor='w')\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2014, 2021):\n",
    "    start_date, end_date = f'{year}-09-01', f'{year+1}-01-31'\n",
    "    plotNetGain(start_date, end_date)\n",
    "    start_date, end_date = f'{year}-01-01', f'{year}-12-31'\n",
    "    plotNetGain(start_date, end_date)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE over interval:\n",
    "def rmse30DayWindow(df):\n",
    "    mse = (df[\"PRICE\"] - df[\"MEAN_PRICE\"]) ** 2\n",
    "    rmse = (mse.mean()) ** .5\n",
    "    return rmse\n",
    "\n",
    "def RMSE(df):\n",
    "    l30, l1, lnormalized = [], [], []\n",
    "    for i in range(0, len(df), 12):\n",
    "        x30 = rmse30DayWindow(df[i:i + 12])\n",
    "        l30.append(x30)\n",
    "    return np.mean(l30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weekly_trend(start_date, end_date, actualPricesFilePath, recommendationPath):\n",
    "    base_date = datetime.strptime(\"2006-01-01\", \"%Y-%m-%d\")\n",
    "    start_idx = (datetime.strptime(start_date, \"%Y-%m-%d\") - base_date).days\n",
    "    end_idx = (datetime.strptime(end_date, \"%Y-%m-%d\") - base_date).days\n",
    "    actual_df = pd.read_csv(actualPricesFilePath, index_col=['DATE'])\n",
    "    actual_df.index = pd.to_datetime(actual_df.index)\n",
    "    fp_ap, fp_an, fn_ap, fn_an = 0, 0, 0, 0\n",
    "    fp_ap_value, fp_an_value, fn_ap_value, fn_an_value = 0, 0, 0, 0\n",
    "    for idx in range(start_idx, end_idx, 84):\n",
    "        p_df = pd.read_csv(os.path.join(recommendationPath, f\"Day_{idx}.csv\"), index_col=['DATE'])\n",
    "        p_df.index = pd.to_datetime(p_df.index)\n",
    "        for dt in p_df.index:\n",
    "            p_df.loc[dt, 'PRICE'] = actual_df.loc[dt:dt+timedelta(days=7), 'PRICE'].mean()\n",
    "        # t_df = pd.merge(p_df, actual_df, left_index=True, right_index=True, how='inner')\n",
    "        for i in range(1, p_df.shape[0]):\n",
    "            a_diff = p_df.iloc[i]['PRICE'] - p_df.iloc[i-1]['PRICE']\n",
    "            f_diff = p_df.iloc[i]['MEAN_PRICE'] - p_df.iloc[i-1]['MEAN_PRICE']\n",
    "            abs_diff = abs(p_df.iloc[i]['MEAN_PRICE'] - p_df.iloc[i]['PRICE'])\n",
    "            if a_diff < 0 and f_diff < 0:\n",
    "                fn_an += 1\n",
    "                fn_an_value += abs_diff\n",
    "            elif a_diff >= 0 and f_diff >= 0:\n",
    "                fp_ap += 1\n",
    "                fp_ap_value += abs_diff\n",
    "            elif a_diff < 0 and f_diff >= 0:\n",
    "                fp_an += 1\n",
    "                fp_an_value += abs_diff\n",
    "            elif a_diff >= 0 and f_diff < 0:\n",
    "                fn_ap += 1\n",
    "                fn_ap_value += abs_diff\n",
    "\n",
    "    count_list = [fp_ap, fn_an, fp_an, fn_ap]\n",
    "    count_total = fp_ap + fp_an + fn_ap + fn_an\n",
    "    \n",
    "    value_list = [fp_ap_value, fn_an_value, fp_an_value, fn_ap_value]\n",
    "    return [ count/count_total for count in count_list], [x/y for x, y in zip(value_list, count_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.2375366568914956, 0.25513196480938416, 0.2375366568914956, 0.2697947214076246], [438.4319122220469, 418.66838777157375, 411.95570915925504, 351.1219665793595])\n"
     ]
    }
   ],
   "source": [
    "start_date, end_date = f'2014-01-01', f'2020-12-31'\n",
    "trends = compute_weekly_trend(start_date, end_date, actualPricesFilePath, withErrorModelFilePath)\n",
    "print(trends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weekly_trend_daily(start_date, end_date, actualPricesFilePath, recommendationPath):\n",
    "    base_date = datetime.strptime(\"2006-01-01\", \"%Y-%m-%d\")\n",
    "    start_idx = (datetime.strptime(start_date, \"%Y-%m-%d\") - base_date).days\n",
    "    end_idx = (datetime.strptime(end_date, \"%Y-%m-%d\") - base_date).days\n",
    "    actual_df = pd.read_csv(actualPricesFilePath, index_col=['DATE'])\n",
    "    actual_df.index = pd.to_datetime(actual_df.index)\n",
    "    fp_ap, fp_an, fn_ap, fn_an = 0, 0, 0, 0\n",
    "    for idx in range(start_idx, end_idx, 7):\n",
    "        p_df = pd.read_csv(os.path.join(recommendationPath, f\"Day_{idx}.csv\"), index_col=['DATE'])\n",
    "        p_df.index = pd.to_datetime(p_df.index)\n",
    "        for dt in p_df.index:\n",
    "            p_df.loc[dt, 'PRICE'] = actual_df.loc[dt:dt+timedelta(days=7), 'PRICE'].mean()\n",
    "        # t_df = pd.merge(p_df, actual_df, left_index=True, right_index=True, how='inner')\n",
    "        for i in range(1, p_df.shape[0]):\n",
    "            a_diff = p_df.iloc[i]['PRICE'] - p_df.iloc[i-1]['PRICE']\n",
    "            f_diff = p_df.iloc[i]['MEAN_PRICE'] - p_df.iloc[i-1]['MEAN_PRICE']\n",
    "            if a_diff < 0 and f_diff < 0:\n",
    "                fn_an = fn_an + 1\n",
    "            elif a_diff >= 0 and f_diff >= 0:\n",
    "                fp_ap = fp_ap + 1\n",
    "            elif a_diff < 0 and f_diff >= 0:\n",
    "                fp_an = fp_an + 1\n",
    "            elif a_diff >= 0 and f_diff < 0:\n",
    "                fn_ap = fn_ap + 1\n",
    "\n",
    "    total = fp_ap + fp_an + fn_ap + fn_an\n",
    "    l = [fp_ap, fn_an, fp_an, fn_ap]\n",
    "    return [ x/total for x in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2466467958271237, 0.22925981122702435, 0.2570789865871833, 0.26701440635866863]\n"
     ]
    }
   ],
   "source": [
    "start_date, end_date = f'2014-01-01', f'2020-12-31'\n",
    "trends_daily = compute_weekly_trend_daily(start_date, end_date, actualPricesFilePath, withErrorModelFilePath)\n",
    "print(trends_daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weekly_mase(start_date, end_date, actualPricesFilePath, recommendationPath):\n",
    "    base_date = datetime.strptime(\"2006-01-01\", \"%Y-%m-%d\")\n",
    "    start_idx = (datetime.strptime(start_date, \"%Y-%m-%d\") - base_date).days\n",
    "    end_idx = (datetime.strptime(end_date, \"%Y-%m-%d\") - base_date).days\n",
    "    actual_df = pd.read_csv(actualPricesFilePath, index_col=['DATE'])\n",
    "    actual_df.index = pd.to_datetime(actual_df.index)\n",
    "    final_df = pd.DataFrame()\n",
    "    for idx in range(start_idx, end_idx, 84):\n",
    "        p_df = pd.read_csv(os.path.join(recommendationPath, f\"Day_{idx}.csv\"), index_col=['DATE'])\n",
    "        p_df.index = pd.to_datetime(p_df.index)\n",
    "        for dt in p_df.index:\n",
    "            p_df.loc[dt, 'PRICE'] = actual_df.loc[dt:dt+timedelta(days=7), 'PRICE'].mean()\n",
    "        # t_df = pd.merge(p_df, actual_df, left_index=True, right_index=True, how='inner')\n",
    "        final_df = pd.concat([final_df, p_df[['PRICE', 'MEAN_PRICE']]])\n",
    "    final_df = final_df[final_df.index <= pd.to_datetime(end_date)]\n",
    "\n",
    "    # mae\n",
    "    final_df['DIFF'] = np.abs(final_df['MEAN_PRICE'] - final_df['PRICE'])\n",
    "    mae = final_df['DIFF'].sum() / final_df.shape[0]\n",
    "    \n",
    "    # mae naive\n",
    "    mae_naive = 0\n",
    "    for i in range(1, final_df.shape[0]):\n",
    "        mae_naive += abs(final_df.iloc[i]['MEAN_PRICE'] - final_df.iloc[i-1]['MEAN_PRICE'])\n",
    "    mae_naive /= (final_df.shape[0] - 1)\n",
    "    print(mae, mae_naive)\n",
    "    return mae / mae_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390.98684176722924 91.04198872003143\n",
      "4.294577120558909\n"
     ]
    }
   ],
   "source": [
    "start_date, end_date = f'2014-01-01', f'2020-12-31'\n",
    "mase = compute_weekly_mase(start_date, end_date, actualPricesFilePath, withErrorModelFilePath)\n",
    "print(mase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(start_date, end_date, actualPricesFilePath, recommendationPath):\n",
    "    base_date = datetime.strptime(\"2006-01-01\", \"%Y-%m-%d\")\n",
    "    start_idx = (datetime.strptime(start_date, \"%Y-%m-%d\") - base_date).days\n",
    "    end_idx = (datetime.strptime(end_date, \"%Y-%m-%d\") - base_date).days\n",
    "    actual_df = pd.read_csv(actualPricesFilePath, index_col=['DATE'])\n",
    "    actual_df.index = pd.to_datetime(actual_df.index)\n",
    "    final_df = pd.DataFrame()\n",
    "    for idx in range(start_idx, end_idx, 84):\n",
    "        p_df = pd.read_csv(os.path.join(recommendationPath, f\"Day_{idx}.csv\"), index_col=['DATE'])\n",
    "        p_df.index = pd.to_datetime(p_df.index)\n",
    "        for dt in p_df.index:\n",
    "            p_df.loc[dt, 'PRICE'] = actual_df.loc[dt:dt+timedelta(days=7), 'PRICE'].mean()\n",
    "        # t_df = pd.merge(p_df, actual_df, left_index=True, right_index=True, how='inner')\n",
    "        final_df = pd.concat([final_df, p_df[['PRICE', 'MEAN_PRICE']]])\n",
    "    final_df = final_df[final_df.index <= pd.to_datetime(end_date)]\n",
    "    n_df = final_df[['PRICE', 'MEAN_PRICE']].copy()\n",
    "    rmse = RMSE(n_df)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685.3200513974855\n"
     ]
    }
   ],
   "source": [
    "start_date, end_date = f'2014-01-08', f'2020-12-31'\n",
    "rmse = compute_rmse(start_date, end_date, actualPricesFilePath, withErrorModelFilePath)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_daily_rmse(start_date, end_date, actualPricesFilePath, recommendationPath):\n",
    "    base_date = datetime.strptime(\"2006-01-01\", \"%Y-%m-%d\")\n",
    "    start_idx = (datetime.strptime(start_date, \"%Y-%m-%d\") - base_date).days\n",
    "    end_idx = (datetime.strptime(end_date, \"%Y-%m-%d\") - base_date).days\n",
    "    actual_df = pd.read_csv(actualPricesFilePath, index_col=['DATE'])\n",
    "    actual_df.index = pd.to_datetime(actual_df.index, format='%Y-%m-%d')\n",
    "    all_rmse = []\n",
    "    for idx in range(start_idx, end_idx+1, 7):\n",
    "        p_df = pd.read_csv(os.path.join(recommendationPath, f\"Day_{idx}.csv\"), index_col=['DATE'])\n",
    "        p_df.index = pd.to_datetime(p_df.index, format='%Y-%m-%d')\n",
    "        for dt in p_df.index:\n",
    "            p_df.loc[dt, 'PRICE'] = actual_df.loc[dt:dt+timedelta(days=7), 'PRICE'].mean()\n",
    "        t_rmse = ((p_df['PRICE'] - p_df['MEAN_PRICE']) ** 2).mean() ** .5\n",
    "        all_rmse.append(t_rmse)\n",
    "    return sum(all_rmse)/len(all_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './EXP3_CYCLIC_RAJASTHAN_KOTA/Recommendations/RetrainFreq15Day/WithErrorModels/Day_3279.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m start_date, end_date \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m2014-01-01\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m2020-12-31\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m daily_rmse \u001b[39m=\u001b[39m compute_daily_rmse(start_date, end_date, actualPricesFilePath, withErrorModelFilePath)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(daily_rmse)\n",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m, in \u001b[0;36mcompute_daily_rmse\u001b[0;34m(start_date, end_date, actualPricesFilePath, recommendationPath)\u001b[0m\n\u001b[1;32m      7\u001b[0m all_rmse \u001b[39m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start_idx, end_idx\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m7\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m     p_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(recommendationPath, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mDay_\u001b[39;49m\u001b[39m{\u001b[39;49;00midx\u001b[39m}\u001b[39;49;00m\u001b[39m.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m), index_col\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mDATE\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     10\u001b[0m     p_df\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(p_df\u001b[39m.\u001b[39mindex, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m     \u001b[39mfor\u001b[39;00m dt \u001b[39min\u001b[39;00m p_df\u001b[39m.\u001b[39mindex:\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './EXP3_CYCLIC_RAJASTHAN_KOTA/Recommendations/RetrainFreq15Day/WithErrorModels/Day_3279.csv'"
     ]
    }
   ],
   "source": [
    "start_date, end_date = f'2014-01-01', f'2020-12-31'\n",
    "daily_rmse = compute_daily_rmse(start_date, end_date, actualPricesFilePath, withErrorModelFilePath)\n",
    "print(daily_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Type': [], 'Duration': [], 'Year': [], 'Rolling RMSE': [], 'Daily RMSE': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- With Error Models ----\n",
      "Seasonal: Year: 2014, Rolling RMSE: 444.3806869667025, Daily RMSE: 474.7154874686746\n",
      "Yearly: Year: 2014, Rolling RMSE: 412.2339714968385, Daily RMSE: 481.29415086047294\n",
      "Seasonal: Year: 2015, Rolling RMSE: 138.48475406063838, Daily RMSE: 215.69863006714007\n",
      "Yearly: Year: 2015, Rolling RMSE: 207.69260466586567, Daily RMSE: 250.86741093533354\n",
      "Seasonal: Year: 2016, Rolling RMSE: 286.45998588958776, Daily RMSE: 301.3401813612108\n",
      "Yearly: Year: 2016, Rolling RMSE: 202.02443725761233, Daily RMSE: 236.33690444962372\n",
      "Seasonal: Year: 2017, Rolling RMSE: 309.12107890679914, Daily RMSE: 263.58189660391133\n",
      "Yearly: Year: 2017, Rolling RMSE: 183.30493833304354, Daily RMSE: 191.77258253121246\n",
      "Seasonal: Year: 2018, Rolling RMSE: 179.72840214326266, Daily RMSE: 197.93532232034843\n",
      "Yearly: Year: 2018, Rolling RMSE: 233.98574715293367, Daily RMSE: 318.03166753226384\n",
      "Seasonal: Year: 2019, Rolling RMSE: 271.9996273515591, Daily RMSE: 318.45072513886157\n",
      "Yearly: Year: 2019, Rolling RMSE: 206.09714263777505, Daily RMSE: 225.64527544180928\n",
      "Seasonal: Year: 2020, Rolling RMSE: 395.94992815263436, Daily RMSE: 428.49811713898424\n",
      "Yearly: Year: 2020, Rolling RMSE: 252.40645383214243, Daily RMSE: 287.7792591514213\n"
     ]
    }
   ],
   "source": [
    "print(\"---- With Error Models ----\")\n",
    "for year in range(2014, 2021):\n",
    "    plotsPath = os.path.join(processedFilePath, 'plots')\n",
    "    if not os.path.exists(plotsPath):\n",
    "        os.makedirs(plotsPath)\n",
    "    start_date, end_date = f'{year}-09-01', f'{year+1}-01-31'\n",
    "    rmse, daily_rmse = compute_rmse(start_date, end_date, actualPricesFilePath, withErrorModelFilePath)\n",
    "\n",
    "    data['Type'].append('Error')\n",
    "    data['Duration'].append('Seasonal')\n",
    "    data['Year'].append(year)\n",
    "    data['Rolling RMSE'].append(rmse)\n",
    "    data['Daily RMSE'].append(daily_rmse)\n",
    "\n",
    "    print(f\"Seasonal: Year: {year}, Rolling RMSE: {rmse}, Daily RMSE: {daily_rmse}\")\n",
    "    start_date, end_date = f'{year}-01-01', f'{year}-12-31'\n",
    "    rmse, daily_rmse = compute_rmse(start_date, end_date, actualPricesFilePath, withErrorModelFilePath)    \n",
    "    print(f\"Yearly: Year: {year}, Rolling RMSE: {rmse}, Daily RMSE: {daily_rmse}\")\n",
    "    \n",
    "    data['Type'].append('Error')\n",
    "    data['Duration'].append('Yearly')\n",
    "    data['Year'].append(year)\n",
    "    data['Rolling RMSE'].append(rmse)\n",
    "    data['Daily RMSE'].append(daily_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Without Error Models ----\n",
      "Seasonal: Year: 2014, Rolling RMSE: 366.05327567567457, Daily RMSE: 399.8329189775516\n",
      "Yearly: Year: 2014, Rolling RMSE: 381.8159590042818, Daily RMSE: 455.9772808008034\n",
      "Seasonal: Year: 2015, Rolling RMSE: 151.10830312867958, Daily RMSE: 223.1352392468516\n",
      "Yearly: Year: 2015, Rolling RMSE: 218.08424272088547, Daily RMSE: 264.0749045100583\n",
      "Seasonal: Year: 2016, Rolling RMSE: 277.8201512477, Daily RMSE: 275.01414383593993\n",
      "Yearly: Year: 2016, Rolling RMSE: 199.51492071999473, Daily RMSE: 239.49342808054425\n",
      "Seasonal: Year: 2017, Rolling RMSE: 400.65269949139264, Daily RMSE: 342.06189935055437\n",
      "Yearly: Year: 2017, Rolling RMSE: 248.53866813364792, Daily RMSE: 259.1271091555911\n",
      "Seasonal: Year: 2018, Rolling RMSE: 185.68208472968422, Daily RMSE: 205.59954447130735\n",
      "Yearly: Year: 2018, Rolling RMSE: 245.043471008195, Daily RMSE: 341.5293136342834\n",
      "Seasonal: Year: 2019, Rolling RMSE: 258.01505026316823, Daily RMSE: 302.9170407622495\n",
      "Yearly: Year: 2019, Rolling RMSE: 225.63768177788856, Daily RMSE: 238.95468603426858\n",
      "Seasonal: Year: 2020, Rolling RMSE: 395.4515128633239, Daily RMSE: 424.03830697252295\n",
      "Yearly: Year: 2020, Rolling RMSE: 279.7484023418659, Daily RMSE: 319.7058365940024\n"
     ]
    }
   ],
   "source": [
    "print(\"---- Without Error Models ----\")\n",
    "for year in range(2014, 2021):\n",
    "    plotsPath = os.path.join(processedFilePath, 'plots')\n",
    "    if not os.path.exists(plotsPath):\n",
    "        os.makedirs(plotsPath)\n",
    "    start_date, end_date = f'{year}-09-01', f'{year+1}-01-31'\n",
    "    # print(withoutErrorModelFilePath)\n",
    "    rmse, daily_rmse = compute_rmse(start_date, end_date, actualPricesFilePath, withoutErrorModelFilePath)    \n",
    "    print(f\"Seasonal: Year: {year}, Rolling RMSE: {rmse}, Daily RMSE: {daily_rmse}\")\n",
    "\n",
    "    data['Type'].append('Without Error')\n",
    "    data['Duration'].append('Seasonal')\n",
    "    data['Year'].append(year)\n",
    "    data['Rolling RMSE'].append(rmse)\n",
    "    data['Daily RMSE'].append(daily_rmse)\n",
    "\n",
    "\n",
    "    start_date, end_date = f'{year}-01-01', f'{year}-12-31'\n",
    "    rmse, daily_rmse = compute_rmse(start_date, end_date, actualPricesFilePath, withoutErrorModelFilePath)    \n",
    "    print(f\"Yearly: Year: {year}, Rolling RMSE: {rmse}, Daily RMSE: {daily_rmse}\")\n",
    "\n",
    "    data['Type'].append('Without Error')\n",
    "    data['Duration'].append('Yearly')\n",
    "    data['Year'].append(year)\n",
    "    data['Rolling RMSE'].append(rmse)\n",
    "    data['Daily RMSE'].append(daily_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling RMSE: \n",
      "246.43504646057502 262.97454190913965\n"
     ]
    }
   ],
   "source": [
    "start_date, end_date = f'2014-01-01', f'2020-12-31'\n",
    "rmse_with, _ = compute_rmse(start_date, end_date, actualPricesFilePath, withErrorModelFilePath)  \n",
    "rmse_without, _ = compute_rmse(start_date, end_date, actualPricesFilePath, withoutErrorModelFilePath)  \n",
    "print(\"Rolling RMSE: \")\n",
    "print(rmse_with, rmse_without)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily RMSE: \n",
      "197.02389599310456 214.83688303152766\n"
     ]
    }
   ],
   "source": [
    "start_date, end_date = f'2014-01-01', f'2020-12-31'\n",
    "rmse_with = compute_daily_rmse(start_date, end_date, actualPricesFilePath, withErrorModelFilePath)  \n",
    "rmse_without = compute_daily_rmse(start_date, end_date, actualPricesFilePath, withoutErrorModelFilePath)  \n",
    "print(\"Daily RMSE: \")\n",
    "print(rmse_with, rmse_without)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Rolling RMSE                                        Daily RMSE  \\\n",
      "Type            Error             Without Error                   Error   \n",
      "Duration     Seasonal      Yearly      Seasonal      Yearly    Seasonal   \n",
      "Year                                                                      \n",
      "2014       179.669095  260.039985    173.207340  258.251118  253.906972   \n",
      "2015       126.388888  152.377172    125.289158  182.901703  169.259621   \n",
      "2016       174.538012  166.944566    205.019425  174.035210  226.799396   \n",
      "2017       196.257473   93.212513    207.820647  121.279303  179.745426   \n",
      "2018       165.349175  156.387631    184.456014  174.190620  172.751900   \n",
      "\n",
      "                                                \n",
      "Type                 Without Error              \n",
      "Duration      Yearly      Seasonal      Yearly  \n",
      "Year                                            \n",
      "2014      309.219812    253.278105  319.632141  \n",
      "2015      185.652953    177.510170  219.668743  \n",
      "2016      204.734904    254.412458  218.108470  \n",
      "2017      100.485361    181.537626  130.404881  \n",
      "2018      180.890082    194.203667  190.452853  \n"
     ]
    }
   ],
   "source": [
    "rmse_df = pd.DataFrame(data)\n",
    "rmse_df = pd.pivot(rmse_df, index='Year', columns=['Type', 'Duration'], values=['Rolling RMSE', 'Daily RMSE'])\n",
    "print(rmse_df.head())\n",
    "# print(processedFilePath)\n",
    "rmse_df.to_csv(os.path.join(os.path.join(processedFilePath, 'metrics'), f'rmse_2014_2020.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7db9c00ba57316717bbc6026097185eeb57bfdc497905db08596415667c38f82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
